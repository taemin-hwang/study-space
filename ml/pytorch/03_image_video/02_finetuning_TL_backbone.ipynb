{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning vs Transfer-learning vs backbone\n",
    "* 딥러닝을 공부하다보면 backbone, fine-tuning, transfer-learning에 대한 용어가 자주 등장합니다\n",
    "* 이 용어들의 차이점을 알아봅시다\n",
    "\n",
    "https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "* 모델의 layer가 많아질수록 학습되는 parameter의 양이 많아지고 학습시간이 증가하게 됩니다\n",
    "* 성능이 좋|은 대부분의 모델엔 수 많은 layer가 있고 학습시간이 수십일까지 걸리기도 합니다\n",
    "* 공개된 모델과 동일한 용도로 사용할 때는 그냥 가져다쓰면 되지만 다른 용도로 사용하고 싶으면 어떡해야 할까요?\n",
    "* 예들을면 30가지 클래스를 분류하는 Object detection model을 개, 고양이 분류 모델로 만들고 싶으면요?\n",
    "* 직접 custom dataset을 구축하고 처음부터 모델을 학습해서 수십일의 시간을 써야할까요?\n",
    "* 이 때 사용하는 것이 `fine-tuning`입니다\n",
    "* `VGGnet`과 같이 이미 학습된 모델에서 feature map 생성부분인 CNN layer와, 분류 부분인 FC layer (Fully-connected layer)만 용도에 맞게 수정해주는 것입니다\n",
    "* 이 때 classification이 아니라 object detection이나 segmentation을 수행하는 모델을 만든다면, CNN layer만 가져다 사용할 수 있는데, 이 CNN layer를 backbone이라 합니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Large, Different Dataset\n",
    "* pre-trained model 학습에 사용된 dataset과 많이 다른 dataset이 있을 때 사용하는 방법입니다\n",
    "* 기존 학습에 사용된 learning-rate의 1/10으로 lr을 적용하여 backbone과 FC layer를 학습합니다\n",
    "* lr을 너무 크게 조정하면 모델이 완전이 새로 학습될 수 있습니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Large, Similar Dataset\n",
    "* Conv. layer는 input과 가까울수록 선, 색 등의 일반적인 특징을 학습하고\n",
    "* output과 가까워질수록 class 분류와 관련된 세세한 특징들을 학습합니다\n",
    "* 유사한 dataset을 사용한다면 시간절약을 위해 Conv. layer의 후반 계층과 FC layer만 학습합니다\n",
    "    * 학습하지 않는 부분은 lr=0, 학습하는 부분은 lr = 기존의 10%로 지정합니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Small, Different Dataset\n",
    "* 가장 challenge한 경우입니다\n",
    "* 데이터가 적기 때문에 overfitting의 위험성이 있어 Conv. layer 전부 학습하는 건 피해야 합니다\n",
    "* Conv. layer에서 어느정도 계층만 학습할 지 `잘` 정해서 학습해야 합니다\n",
    "* classification을 담당하는 FC layer는 모두 학습합니다 (data augmentation을 이용할 수 있음)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Small, Similar Dataset\n",
    "* Conv. layer는 학습하지 않고 (Overfitting), FC layer만 학습합니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주의할 점\n",
    "* Fine-tuning은 이미 학습된 안정적인 가중치를 `조금씩` 바꾸는 방법입니다\n",
    "* 따라서 새로운 layer를 붙이는 것에 주의를 기울여야 합니다\n",
    "    * learning rate를 작게 설정하기 (기존의 1/10)\n",
    "    * 안정성있는 optimizer 사용하기 (SGD 등)\n",
    "    * bottleneck feature만 따로 저장해서 FC layer를 학습시키기 (데이터가 충분히 있을 때만)\n",
    "    * 모든 layer는 1번이상 학습이 완료된 상태여야 함 (random weight가 할당되어서는 안됨)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "* 거의 transfer learning = fine-tuning이라 봐도 무방\n",
    "* 가령 object detection이나 segmentation 문제에서 resnet CNN에서 classification (FC layer)를 제거하고\n",
    "* feature extraction으로 사용하면 resnet의 CNN을 backbone으로 썼다라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
