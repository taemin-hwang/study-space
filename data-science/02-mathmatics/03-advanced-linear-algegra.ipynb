{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 고급 선형대수\n",
    "## 3.1 선형대수와 해석기하의 기초\n",
    "\n",
    "선형대수는 숫자 데이터의 계산에만 사용되는 것이 아니다\n",
    "\n",
    "직선과 화살표, 이미지 등을 다루는 기하학에서도 선형대수는 중요한 역할을 한다\n",
    "\n",
    "이 절에서는 선형대수를 기하학에서 어떻게 응용하고 선형대수의 연산이 기하학적으로 어떤 의미를 가지는지 알아본다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 기하학적 의미\n",
    "$N$차원 벡터 $a$는 $N$차원 공간에서\n",
    "* 벡터 $a$의 값으로 표시되는 점(point) 또는\n",
    "* 원점과 벡터 $a$의 값으로 표시되는 점을 연결한 화살표 (arrow)\n",
    "라고 생각할 수 있다\n",
    "\n",
    "예를 들어 2차원 벡터\n",
    "\n",
    "$$ a = \\left[ \\begin{matrix} a_1 \\\\ a_2 \\end{matrix}  \\right] $$\n",
    "는 $(a_1, a_2)$ 좌표의 점으로 생각할 수도 있고, 원점에서 이 점을 가리키는 화살표로 생각할 수도 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 길이\n",
    "벡터 $a$의 길이는 놈(norm)으로 $\\Vert a \\Vert$로 정의한다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 선형 조합\n",
    "여러 개의 벡터를 스칼라곱을 한 후 더한 것을 선형조합 (linear combination)이라 한다\n",
    "\n",
    "$$ c_1x_1 + c_2x_2 + ... + c_Nx_N $$\n",
    "\n",
    "이 식에서 $c$는 스칼라 계수다\n",
    "\n",
    "결국 선형 조합은 입력 벡터 $x$와 가중치 $c$의 연산으로 생각할 수 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 1]]\n",
      "[[ 3 -1]\n",
      " [ 1 -1]]\n",
      "[[-0.33333333 -0.33333333]\n",
      " [ 1.66666667 -0.33333333]]\n",
      "[[ 3. -1.]\n",
      " [ 1. -1.]]\n",
      "c1, c2 \n",
      " [-0.33333333  1.66666667]\n",
      "c1, c2 \n",
      " [-0.33333333 -0.33333333]\n",
      "2.9999000000000002\n",
      "1.0\n",
      "-0.9999\n",
      "-0.9999\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 2])\n",
    "x2 = np.array([2, 1])\n",
    "\n",
    "y1 = np.array([3, 1])\n",
    "y2 = np.array([-1, -1])\n",
    "\n",
    "x = np.vstack((x1, x2))\n",
    "y = np.vstack((y1, y2))\n",
    "y = y.T\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "c = np.linalg.lstsq(x, y, rcond=None)\n",
    "print(c[0])\n",
    "\n",
    "print(x @ c[0])\n",
    "\n",
    "print(\"c1, c2 \\n\", np.linalg.inv(x) @ np.array([3, 1]).T)\n",
    "print(\"c1, c2 \\n\", np.linalg.inv(x) @ np.array([-1, -1]).T)\n",
    "\n",
    "print(-0.3333*1 + 1.6666*2)\n",
    "print(-0.3333*2 + 1.6666*1)\n",
    "\n",
    "print(-0.3333*1 + -0.3333*2)\n",
    "print(-0.3333*2 + -0.3333*1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적과 삼각함수\n",
    "\n",
    "두 벡터의 내적은 벡터의 길이 $\\Vert a \\Vert$, $\\Vert b \\Vert$와 두 벡터 사이의 각도 $\\theta$의 코사인 함수 값으로 계산할 수 있다\n",
    "\n",
    "$$ a^Tb = \\Vert a \\Vert \\Vert b \\Vert cos \\theta $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 벡터 $a$와 $b$가 이루는 각도가 90도이면 서로 직교 (orthogonal)하다고 말한다\n",
    "이때 서로 직교인 두 벡터의 내적은 0이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 1]) # [1 1]T\n",
    "b = np.array([-1, 1]) # [-1 1]T\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 3.1.3\n",
    "다음 두 벡터에 대해 모두 직교하는 단위벡터를 찾아라\n",
    "\n",
    "$$ x = \\left[ \\begin{matrix} 1 \\\\ 1 \\\\ 0 \\end{matrix} \\right], \n",
    "y = \\left[ \\begin{matrix} 1 \\\\ 0 \\\\ 0 \\end{matrix} \\right] $$\n",
    "\n",
    "$$ Ax = Ay = \\left[ \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\right] $$\n",
    "\n",
    "$$ A\\left[\\begin{matrix}x & y\\end{matrix}\\right] = \\left[ \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\right] $$\n",
    "\n",
    "$$ A\\left[\\begin{matrix} 1 & 0 \\\\ 1 & 0 \\\\ 0 & 0 \\end{matrix}\\right] = \\left[ \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\right] $$\n",
    "\n",
    "$$ \\left[\\begin{matrix} 1 & 1 & 0 \\\\ 0 & 0 & 0 \\end{matrix} \\right] A^T = \\left[ \\begin{matrix} 0 & 0 & 0 \\end{matrix} \\right] $$\n",
    "\n",
    "\n",
    "$Ax = 0$ 선형 시스템의 해는 Total least square에 의해 SVD 특이값 분해 결과의 V의 마지막 열과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 1, 0], [1, 0, 0]])\n",
    "u, s, v = np.linalg.svd(x)\n",
    "v[:, -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도\n",
    "두 벡터의 방향이 비슷할수록 벡터가 비슷하다고 간주하면\n",
    "\n",
    "두 벡터 사이의 코사인 값을 이용해 코사인 유사도를 구할 수 있다\n",
    "\n",
    "코사인 값은 각도가 0일 때 1로 가장 크기 때문에 같은 방향을 가리키면 코사인 유사도가 1을 가진다\n",
    "\n",
    "$$ cosine similarity = cos \\theta = {x^Ty \\over \\Vert x \\Vert \\Vert y \\Vert} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 분해와 성분\n",
    "\n",
    "어떤 두 벡터 $a$와 $b$의 합이 다른 벡터 $c$가 될 때 $c$가 두 벡터 성분 (component) $a, b$로 분해된다고 말한다 (decomposition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 투영 성분과 직교 성분 (projection, rejection)\n",
    "벡터 $a$를 다른 벡터 $b$에 직교하는 성분과 벡터 $b$에 평행한 성분으로 분해할 수 있다\n",
    "\n",
    "* 평행한 성분: 백터 $b$에 대한 투영 성분 (projection)\n",
    "* 직교하는 성분: 벡터 $b$에 대한 직교 성분 (rejection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 좌표와 변환\n",
    "벡터의 선형독립과 랭크에 개념을 알아보고\n",
    "\n",
    "기저 벡터와 좌표변환이 선형대수와 어떤 연관이 있는지 공부한다\n",
    "\n",
    "좌표변환은 이미지 처리 작업뿐 아니라 다변수 확률변수를 분석하는데도 사용된다\n",
    "\n",
    "### 선형 종속과 선형 독립\n",
    "벡터 집합 $x_1, x_2, ..., x_N$을 이루는 벡터의 선형조합이 0벡터가 되도록 하는 스칼라 계수\n",
    "\n",
    "$c_1,c_2, ..., c_N$이 존재하면 벡터들이 선형 종속 (linearly dependent)하다고 한다\n",
    "\n",
    "단 $c$가 영벡터인 경우는 제외한다\n",
    "\n",
    "$$ c_1x_1 + c_2x_2 + ... + c_Nx_N = 0 $$\n",
    "\n",
    "반대로 $c$가 존재하지 않으면 벡터들이 선형 독립 (linearly independent)하다고 한다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형독립과 선형 연립방정식\n",
    "선형독립 관계를 행렬과 벡터의 곱으로 나타낼 수도 있다\n",
    "\n",
    "$$ c_1x_1 + c_2x_2 + ... + c_Nx_N = Xc = 0 $$\n",
    "\n",
    "이 연립방정식의 해가 영벡터밖에 없으면 선형독립이다\n",
    "\n",
    "(Least square 문제에서 residual이 0이면 되지 않나?; `lstsq`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형종속인 경우 (X를 영벡터로 만드는 c벡터가 있는 경우)\n",
    "* 경우 1: 벡터의 개수가 벡터의 차원보다 클 때\n",
    "* 경우 2: 값이 같은 벡터가 있을 때\n",
    "* 경우 3: 어떤 벡터가 다른 벡터의 선형조합일 때\n",
    "\n",
    "국, 영, 수 점수와 (국+영+수)/3 점수는 서로 선형조합이다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랭크\n",
    "행렬의 열벡터 중 서로 독립인 열벡터의 최대 개수: 열랭크 (column rank)\n",
    "\n",
    "행렬의 행벡터 중 서로 독립인 행벡터의 최대 개수: 행랭크 (row rank)\n",
    "\n",
    "* 행랭크와 열랭크는 항상 같다 = 그냥 랭크 (rank)\n",
    "\n",
    "행렬 $A$의 랭크는 기호로 $rankA$로 표시한다\n",
    "\n",
    "$$ rankA \\leq min(M, N) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 (numpy matrix_rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([[1, 3], [2, 4]])\n",
    "print(np.linalg.matrix_rank(X1))\n",
    "\n",
    "X2 = np.array([[1, 3, 5], [2, 4, 7]])\n",
    "print(np.linalg.matrix_rank(X2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀랭크\n",
    "$ rankA = min(M, N) $을 만족하는 행렬을 풀랭크라고 한다\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로우-랭크 행렬 (low-rank matrix)\n",
    "$N$차원 벡터 $x$ 하나를 이용하여 만들어지는 다음과 같은 행렬을 랭크-1 행렬 (rank-1 matrix)라고 한다\n",
    "\n",
    "$$ {x x^T} \\in \\mathbb{R}^{N \\times N} $$\n",
    "\n",
    "이 행렬의 열벡터들은 $x$라고 하는 하나의 벡터를 하나의 벡터를 $x_1$배, $x_2$배, ... 한 벡터이므로 독립적인 열벡터는 1개다\n",
    "\n",
    "따라서 랭크-1 행렬의 랭크는 1이다\n",
    "\n",
    "$$ A = xx^T = \\left[ \\begin{matrix} 1 \\\\ 2 \\end{matrix} \\right] \\left[ \\begin{matrix} 1 & 2 \\end{matrix} \\right]\n",
    "= \\left[ \\begin{matrix} 1 & 2 \\\\ 2 & 4 \\end{matrix} \\right] $$\n",
    "\n",
    "$$ rankA = 1 $$\n",
    "\n",
    "앞서 비슷한 방법으로 선형 독립인 두 개의 $N$ 차원 백터 $x_1, x_2$를 이용하면 랭크-2 행렬을 만들 수 있다\n",
    "\n",
    "마찬가지로 $M$개의 $N$차원 벡터를 이용하면 랭크-M 행렬이 된다\n",
    "\n",
    "이러한 행렬들을 가리켜 로우-랭크 행렬 (low-rank matrix)라고 한다\n",
    "\n",
    "이 로우-랭크 행렬은 나중에 특이 분해 (singular value decomposition)과 PCA (principal component analysis)에서 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 1])\n",
    "A = x1 @ x1.T\n",
    "\n",
    "print(A)\n",
    "print(np.linalg.matrix_rank(A))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터공간과 기저벡터 (vector space, basis vector)\n",
    "여러 벡터를 선형조합하면 다른 벡터를 만들 수 있다\n",
    "\n",
    "벡터 $N$개가 서로 선형 독립이면 이 벡터를 선형조합하여 만들어지는 모든 벡터의 집합을\n",
    "\n",
    "벡터공간 (vector space) $V$라고 하고 이 벡터공간의 차원을 $N$이라 한다\n",
    "\n",
    "그리고 그 벡터들을 벡터공간의 기저벡터 (basis vector)라고 한다\n",
    "\n",
    "$$ V = \\left[ c_1x_1 + ... + c_Nx_N | c_1,  ... , c_N \\in \\mathbb{R} \\right] $$\n",
    "\n",
    "$N$개의 $N$차원 벡터 $x_1, x_2, ..., x_N$이 선형독립이면 이를 선형조합하여 모든 $N$차원 벡터를 만들 수 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랭크와 역행렬\n",
    "정방행렬의 랭크과 역행렬 사이에는 다음과 같은 정리가 성립한다\n",
    "\n",
    "정방행렬이 풀랭크면 역행렬이 존재한다. 역도 성립한다. 즉, 정방행렬의 역행열이 존재하면 풀랭크다 **\n",
    "\n",
    "### 벡터공간 투영\n",
    "$M$개의 $N$차원 기저벡터 $v_1, v_2, ..., v_M$가 존재한다고 하자\n",
    "\n",
    "$M$은 $N$보다 작다. 이 때 모든 $N$차원 벡터 $x$에 대해 기저벡터 $v_1, v_2, ..., v_M$을 선형조합해 단든 벡터,,,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표준 기저 벡터 (standard basis vector)\n",
    "크기가 1인 X, Y, Z와도 같은 벡터\n",
    "\n",
    "$$ e_1 = \\left[  \\begin{matrix} 1 \\\\ 0 \\\\ ... \\\\ 0 \\end{matrix} \\right],\n",
    "e_2 = \\left[  \\begin{matrix} 0 \\\\ 1 \\\\ ... \\\\ 0 \\end{matrix} \\right],\n",
    "...\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좌표\n",
    "\n",
    "어떤 벡터의 좌표 (coordinate)는 기저벡터를 선형조합하여 벡터를 표현하기 위한 계수를 말한다\n",
    "\n",
    "예를 들어 다음처럼 기저벡터 $ \\{ e_1, e_2 \\} $를 선형조합해 벡터 $x$를 나타낼 수 있다고 하면\n",
    "\n",
    "$$ x = x_{e_1}e_1 + x_{e_2}e_2 $$\n",
    "\n",
    "이 때 벡터 $x_e$\n",
    "\n",
    "$$ x_e = \\left[ \\begin{matrix} x_{e_1} \\\\ x_{e_2} \\end{matrix} \\right] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변환행렬\n",
    "원래의 기저벡터가 아닌 새로운 기저벡터가 있다고 하자 (좌표계가 다르다고 이해하면 된다)\n",
    "\n",
    "이 새로운 기저벡터들의 기존 기저벡터에 대한 좌표를 열벡터로 보고 이를 행렬로 묶은 행렬 $A$를 생각하자\n",
    "\n",
    "예를 들어, 기존의 기저벡터가 $\\{ e_1, e_2 \\} $이고 새로운 기저벡터 $\\{ g_1, g_2 \\} $ 간에 다음과 같은 관계가 성립한다면\n",
    "\n",
    "$$ g1 = k_{11}e_1 + k_{12}e_2 \\\\ g2 = k_{21}e_1 + k_{22}e_2 $$\n",
    "\n",
    "$$ A = \\left[ \\begin{matrix} k_{11} & k_{12} \\\\ k_{21} & k_{22} \\end{matrix} \\right] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좌표변환\n",
    "새로운 기저벡터에 대해 좌표를 계산하는 것을 좌표변환 (coordinate transform)이라고 한다\n",
    "\n",
    "기저벡터가 달라지더라도 좌푯값이 가리키는 실제 위치는 원래의 벡터가 가리키는 위치와 같아야 하므로\n",
    "\n",
    "$$ x = x_{e_1}e_1 + x_{e_2}e_2 = x_{g_1}g_1 + x_{g_2}g_2 $$\n",
    "$$ x = [ \\begin{matrix} e_1 & e_2 \\end{matrix}]x_e = [ \\begin{matrix} g_1 & g_2 \\end{matrix}]x_g $$\n",
    "\n",
    "\n",
    "$ (A^T)^{-1} $이 $x_e$를 $x_g$로 변환하는 변환행렬이다\n",
    "\n",
    "즉 새로운 좌표벡터는 원래의 좌표벡터에 변환행렬을 곱하여 구할 수 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 변환\n",
    "\n",
    "새로운 기저벡터에 대한 좌표변환을 응용하면 이미지를 자유롭게 변환할 수도 있다\n",
    "\n",
    "파이썬에서는 `scipy.ndimage`의 `affine_transform()` 명령을 사용한다\n",
    "\n",
    "이 명령은 이미지를 이루는 픽셀을 새로운 좌표로 이동시킨다\n",
    "\n",
    "인수로는 이미지와 변환행렬의 역행렬을 받는다\n",
    "\n",
    "파이썬 이미지에서는 다음과 같은 표준 기저벡터를 사용한다 ($x_1$이 아래를 향하는 세로축, $x_2$가 오른쪽을 향하는 가로축)\n",
    "\n",
    "$$ e_1 = \\left[ \\begin{matrix} 0 \\\\ -1 \\end{matrix} \\right], e_2 = \\left[ \\begin{matrix} 1 \\\\ 0 \\end{matrix} \\right] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 고윳값 분해 (eigen-decomposition)\n",
    "\n",
    "분해를 통해 행렬의 내부 구조를 살펴보거나 행렬을 이용한 연산을 더 효울적으로 할 수 있다\n",
    "\n",
    "### 고윳값과 고유벡터 (eigen value, eigen vector)\n",
    "정방 행렬 $A$에 대해 다음 식을 만족하는 영벡터가 아닌 벡터 $v$를 고유벡터 (eigen vector)라 부른다\n",
    "\n",
    "$$ Av = \\lambda v $$\n",
    "\n",
    "eigen value와 eigen vector를 찾는 작업을 eigen-decomposition이라 부른다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제\n",
    "\n",
    "행렬 $A$\n",
    "\n",
    "$$ A = \\left[ \\begin{matrix} 1 & -2 \\\\ 2 & -3  \\end{matrix} \\right]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성방정식\n",
    "행렬만 주어졌을 때 고윳값과 고유벡터는 어떻게 구할 수 있을까?\n",
    "\n",
    "행렬 $A$의 고윳값은 $A - \\lambda I $의 행렬식이 0이 되도록 하는 특성방정식을 구하면 된다\n",
    "\n",
    "$$ det(A - \\lambda I) = 0 $$\n",
    "\n",
    "$ det(A - \\lambda I) = 0 $이라는 의미는 $ A - \\lambda I $의 역행렬이 존재하지 않는다는 뜻이다 (0으로 나눠지니까)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고윳값의 개수\n",
    "$N$차 방정식이 항상 $N$개의 복소수 해를 가진다는 사실을 이용하면 $N$차원 정방행렬의 고윳값 개수에 대해 다음 정리가 성립한다\n",
    "\n",
    "중복된 고윳값을 각각 별개로 생각하고 복소수인 고윳값도 고려한다면 $N$차원 정방행렬의 고윳값은 항상 $N$개다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고윳값과 대각합/행렬식\n",
    "어떤 행렬의 고윳값이 $\\lambda_1, \\lambda_2, ..., \\lambda_N$이라고 하면 모든 고윳값의 곱은 행렬식의 값 (determinant)과 같고 모든 고윳값의 합은 대각합(trace)와 같다\n",
    "\n",
    "$$ det(A) = \\prod_{i=1}^N{\\lambda_i} $$\n",
    "\n",
    "$$ trace(A) = \\sum_{i=1}^N{\\lambda_i} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고유벡터의 계산\n",
    "고윳값을 알면 다음 연린 방정식을 풀어 고유벡터를 구할 수 있다\n",
    "\n",
    "$$ (A - \\lambda I)v = 0 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대각화\n",
    "$N$차원의 정방행렬 $A$가 $N$가의 복소수 고윳값과 이에 대응하는 고유 벡털르 가진다는 성질을 이용하면 다음처럼 행렬을 분해할 수 있다\n",
    "\n",
    "행렬 $A$의 고윳값과 이에 대응하는 단위벡터인 고유벡터를 각각\n",
    "\n",
    "$$ \\lambda_1, \\lambda_2, ..., \\lambda_N, v_1, v_2, ..., v_N $$\n",
    "\n",
    "이라고 하자\n",
    "\n",
    "이 고윳값과 고유벡터를 묶어서 고유벡터행렬, 고윳값행렬을 정의할 수 있따\n",
    "\n",
    "고유벡터행렬 $V$는 고유벡터를 열벡터로 옆으로 쌓아서 만든 행렬이다\n",
    "\n",
    "고윳값행렬 $\\Lambda$는 고윳값을 대각성분으로 가지는 대각행렬이다\n",
    "\n",
    "$$ AV = V\\Lambda $$\n",
    "\n",
    "만약 고유행렬벡터 $V$의 역행렬이 존재한다면..\n",
    "\n",
    "$$ A = V\\Lambda V^{-1} $$\n",
    "\n",
    "고유벡터행렬과 고윳갑행렬의 곱으로 표현할 수 있다 (이를 행렬의 대각화 (diagonalization)이라 한다)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대각화가능\n",
    "행렬이 대각화 가능하려면 고유벡터가 선형독립이어야 한다\n",
    "\n",
    "대각화가능(diagonalizable) 행렬..\n",
    "* 고유벡터인 열벡터로 이루어진 고유벡터행렬의 역행렬이 존재하면 대각화가 가능한다\n",
    "* 그런데 정방행렬의 역행렬이 존재할 조건은 정방행렬의 열벡터가 선형독립일 경우이다\n",
    "* 따라서 행렬이 대각화 가능하려면 고유벡터가 선형 독립이어야 한다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고윳값과 역행렬\n",
    "[정리] 대각화 가능한 행렬에 0인 고유값이 없으면 항상 역행렬이 존재한다\n",
    "\n",
    "행렬 $A$가 대각화 가능하면 다음처럼 표현할 수 있다\n",
    "\n",
    "$$ A = V\\Lambda V^-1 $$\n",
    "\n",
    "이 행렬의 역행렬은 다음과 같이 계산한다\n",
    "\n",
    "$$ A^{-1} = (V\\Lambda V^{-1})^{-1} = V  \\Lambda^{-1} V^{-1}$$\n",
    "\n",
    "대각행렬의 역행렬은 각 대각성분의 역수로 이루어진 대각행렬이므로 0인 고윳값만 없으면 항상 역행렬이 존재한다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대칭행렬의 고유분해\n",
    "[정리] 행렬 $A$가 실수인 대칭행렬이면 고유값이 실수이고 고유벡터는 서로 직교(orthogonal)한다\n",
    "\n",
    "cf. 대칭행렬이란, $A = A^T$를 만족하는 행렬\n",
    "\n",
    "cf. [정리] 행렬이 대각화 가능하려면 고유벡터가 선형독립이어야 한다 (= 선형조합으로 0벡터를 만들기위해서는 계수가 반드시 0이어야 한다)\n",
    "\n",
    "고유벡터들이 크기가 1이 되도록 정규화된 상태라면 고유벡터 행렬 $V$는 정규직교(orthonormal) 행렬이므로 전치행렬이 역행렬이다\n",
    "\n",
    "$$ V^TV = VV^T = I $$\n",
    "\n",
    "$$ V^{-1} = V^T $$\n",
    "\n",
    "$$ A = V\\Lambda V^T $$\n",
    "\n",
    "[정리] 실수인 대칭행렬은 항상 대각화 가능하다\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 특이값 분해 (Singular value decomposition; SVD)\n",
    "\n",
    "정방행렬은 고유분해로 eigen value, eigen vector를 찾을 수 있었다\n",
    "\n",
    "정방행렬이 아닌 행렬은 고유분해가 불가능하지만, 대신 고유분해와 비슷한 특이분해를 할 수 있다\n",
    "\n",
    "### 특이값과 특이벡터\n",
    "\n",
    "$N \\times M$크기의 행렬 $A$를 다음과 같은 3개의 행렬의 곱으로 나타내는 것을 특이분해 (singular decomposition)이라 한다\n",
    "\n",
    "$$ A = U\\Sigma V^T $$\n",
    "\n",
    "여기에서 $U$, $\\Sigma$, $V$는 다음 조건을 만족해야 한다\n",
    "* $U$는 $N$차원 정방행렬로 모든 열벡터가 단위벡터이고 서로 직교한다\n",
    "* $\\Sigma$는 대각성분이 양수인 대각행렬이고, *큰 수부터 작은 수 순서로 배열한다* ***\n",
    "* $V$는 $M$차원 정방행렬로 모든 열벡터가 단위벡터이고 서로 직교한다\n",
    "\n",
    "[정리] 특이 분해는 모든 행렬에 대해 가능하다. 즉 어떤 행렬이 주어지더라도 위와 같이 특이분해 할 수 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특이값 분해의 축소형\n",
    "\n",
    "특이값 대각행렬에서 0인 부분은 사실상 아무런 의미가 없기 때문에 대각행렬의 0원소부분과 대응하는 특이 벡터를 없애도 원래 행렬이 나온다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특이값과 특이벡터의 관계\n",
    "행렬 $V$는 정규직교 행렬이므로 전치행렬이 역행렬이다\n",
    "$$ V^T = V^{-1} $$\n",
    "\n",
    "특이분해된 등식의 양변에 $V$를 곱하면,\n",
    "\n",
    "$$ AV = U\\Sigma V^TV = U\\Sigma $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차원 근사\n",
    "\n",
    "2차원 평면위에 3개의 2차원 벡터 $a_1, a_2, a_3$가 있다\n",
    "\n",
    "원점을 지나면서도 모든 점들과 가능한 가까이 있는 직선을 만들고 싶다면 직선의 방향을 어떻게 해야할께\n",
    "\n",
    "직선의 방향을 나타내는 단위벡터를 $w$라고 하자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
